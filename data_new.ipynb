{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang diperlukan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n",
      "  patterns       tag                                          responses\n",
      "0    hallo  greeting  [Hai! Unibot di sini. Ada yang bisa saya bantu...\n",
      "1      hai  greeting  [Hai! Unibot di sini. Ada yang bisa saya bantu...\n",
      "2     halo  greeting  [Hai! Unibot di sini. Ada yang bisa saya bantu...\n",
      "3      hei  greeting  [Hai! Unibot di sini. Ada yang bisa saya bantu...\n",
      "4       hi  greeting  [Hai! Unibot di sini. Ada yang bisa saya bantu...\n",
      "\n",
      "Total patterns: 2922\n",
      "Unique tags: 750\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "with open('Data_New.json', encoding='utf-8') as content:\n",
    "    data = json.load(content)\n",
    "\n",
    "# Persiapkan data\n",
    "patterns = []\n",
    "tags = []\n",
    "responses = []\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        patterns.append(pattern.lower())  # Lowercase untuk konsistensi\n",
    "        tags.append(intent['tag'])\n",
    "        responses.append(intent['responses'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'patterns': patterns,\n",
    "    'tag': tags,\n",
    "    'responses': responses\n",
    "})\n",
    "\n",
    "# Tampilkan beberapa data untuk memastikan struktur yang benar\n",
    "print(\"Sample data:\")\n",
    "print(df.head())\n",
    "print(\"\\nTotal patterns:\", len(patterns))\n",
    "print(\"Unique tags:\", len(set(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi patterns\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['patterns'])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert patterns ke sequences\n",
    "X = tokenizer.texts_to_sequences(df['patterns'])\n",
    "max_seq_len = max([len(x) for x in X])\n",
    "X_pad = pad_sequences(X, maxlen=max_seq_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size: 318\n",
      "Max sequence length: 12\n",
      "Number of classes: 750\n"
     ]
    }
   ],
   "source": [
    "# Encode tags\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['tag'])\n",
    "\n",
    "print(\"\\nVocabulary size:\", total_words)\n",
    "print(\"Max sequence length:\", max_seq_len)\n",
    "print(\"Number of classes:\", len(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moham\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Buat model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 128, input_length=max_seq_len),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.0030 - loss: 6.6200 - val_accuracy: 0.0000e+00 - val_loss: 6.6548\n",
      "Epoch 2/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0054 - loss: 6.5978 - val_accuracy: 0.0000e+00 - val_loss: 7.3094\n",
      "Epoch 3/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0107 - loss: 6.5008 - val_accuracy: 0.0000e+00 - val_loss: 7.8653\n",
      "Epoch 4/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0072 - loss: 6.4495 - val_accuracy: 0.0000e+00 - val_loss: 8.6157\n",
      "Epoch 5/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0107 - loss: 6.3489 - val_accuracy: 0.0000e+00 - val_loss: 9.4822\n",
      "Epoch 6/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0061 - loss: 6.1446 - val_accuracy: 0.0000e+00 - val_loss: 10.0432\n",
      "Epoch 7/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0154 - loss: 5.8981 - val_accuracy: 0.0000e+00 - val_loss: 11.4539\n",
      "Epoch 8/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0087 - loss: 5.7888 - val_accuracy: 0.0000e+00 - val_loss: 10.6651\n",
      "Epoch 9/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0067 - loss: 5.6738 - val_accuracy: 0.0000e+00 - val_loss: 11.8902\n",
      "Epoch 10/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0142 - loss: 5.5740 - val_accuracy: 0.0000e+00 - val_loss: 12.6701\n",
      "Epoch 11/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0139 - loss: 5.4545 - val_accuracy: 0.0017 - val_loss: 13.6050\n",
      "Epoch 12/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0222 - loss: 5.2765 - val_accuracy: 0.0000e+00 - val_loss: 13.7250\n",
      "Epoch 13/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0230 - loss: 5.1828 - val_accuracy: 0.0000e+00 - val_loss: 14.6032\n",
      "Epoch 14/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0268 - loss: 5.0566 - val_accuracy: 0.0000e+00 - val_loss: 15.2470\n",
      "Epoch 15/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0194 - loss: 4.9796 - val_accuracy: 0.0000e+00 - val_loss: 15.8061\n",
      "Epoch 16/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0266 - loss: 4.9069 - val_accuracy: 0.0000e+00 - val_loss: 15.6469\n",
      "Epoch 17/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0306 - loss: 4.8386 - val_accuracy: 0.0000e+00 - val_loss: 16.4390\n",
      "Epoch 18/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0286 - loss: 4.7844 - val_accuracy: 0.0000e+00 - val_loss: 15.8974\n",
      "Epoch 19/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0385 - loss: 4.6934 - val_accuracy: 0.0000e+00 - val_loss: 16.4127\n",
      "Epoch 20/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0343 - loss: 4.6094 - val_accuracy: 0.0000e+00 - val_loss: 16.9998\n",
      "Epoch 21/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0338 - loss: 4.5521 - val_accuracy: 0.0000e+00 - val_loss: 17.0499\n",
      "Epoch 22/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0423 - loss: 4.4427 - val_accuracy: 0.0000e+00 - val_loss: 17.4294\n",
      "Epoch 23/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0480 - loss: 4.4148 - val_accuracy: 0.0000e+00 - val_loss: 18.1441\n",
      "Epoch 24/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0560 - loss: 4.3783 - val_accuracy: 0.0051 - val_loss: 18.7634\n",
      "Epoch 25/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0344 - loss: 4.3287 - val_accuracy: 0.0000e+00 - val_loss: 18.8844\n",
      "Epoch 26/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0468 - loss: 4.2322 - val_accuracy: 0.0000e+00 - val_loss: 18.9174\n",
      "Epoch 27/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0428 - loss: 4.2284 - val_accuracy: 0.0000e+00 - val_loss: 19.1841\n",
      "Epoch 28/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0392 - loss: 4.1840 - val_accuracy: 0.0017 - val_loss: 19.2686\n",
      "Epoch 29/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0357 - loss: 4.1264 - val_accuracy: 0.0068 - val_loss: 19.3505\n",
      "Epoch 30/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0439 - loss: 4.0647 - val_accuracy: 0.0068 - val_loss: 20.0468\n",
      "Epoch 31/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0484 - loss: 4.0505 - val_accuracy: 0.0000e+00 - val_loss: 20.1240\n",
      "Epoch 32/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0475 - loss: 4.0204 - val_accuracy: 0.0000e+00 - val_loss: 19.9457\n",
      "Epoch 33/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0488 - loss: 3.9753 - val_accuracy: 0.0017 - val_loss: 20.5250\n",
      "Epoch 34/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0571 - loss: 3.9159 - val_accuracy: 0.0068 - val_loss: 20.9393\n",
      "Epoch 35/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0630 - loss: 3.8847 - val_accuracy: 0.0068 - val_loss: 21.0545\n",
      "Epoch 36/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0633 - loss: 3.8876 - val_accuracy: 0.0068 - val_loss: 21.2685\n",
      "Epoch 37/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0565 - loss: 3.8248 - val_accuracy: 0.0068 - val_loss: 21.4127\n",
      "Epoch 38/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0596 - loss: 3.8303 - val_accuracy: 0.0000e+00 - val_loss: 21.8740\n",
      "Epoch 39/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0669 - loss: 3.7818 - val_accuracy: 0.0034 - val_loss: 21.9890\n",
      "Epoch 40/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0687 - loss: 3.7238 - val_accuracy: 0.0000e+00 - val_loss: 21.9091\n",
      "Epoch 41/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0674 - loss: 3.7118 - val_accuracy: 0.0000e+00 - val_loss: 22.5756\n",
      "Epoch 42/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0687 - loss: 3.7035 - val_accuracy: 0.0000e+00 - val_loss: 22.7632\n",
      "Epoch 43/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0726 - loss: 3.6864 - val_accuracy: 0.0034 - val_loss: 22.9978\n",
      "Epoch 44/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0668 - loss: 3.6657 - val_accuracy: 0.0051 - val_loss: 22.7769\n",
      "Epoch 45/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0789 - loss: 3.6195 - val_accuracy: 0.0000e+00 - val_loss: 23.2910\n",
      "Epoch 46/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0848 - loss: 3.5882 - val_accuracy: 0.0068 - val_loss: 23.7327\n",
      "Epoch 47/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0861 - loss: 3.5898 - val_accuracy: 0.0137 - val_loss: 23.7633\n",
      "Epoch 48/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0826 - loss: 3.5529 - val_accuracy: 0.0017 - val_loss: 23.7293\n",
      "Epoch 49/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0771 - loss: 3.5436 - val_accuracy: 0.0154 - val_loss: 24.5540\n",
      "Epoch 50/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0740 - loss: 3.4808 - val_accuracy: 0.0085 - val_loss: 24.5398\n",
      "Epoch 51/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0915 - loss: 3.4887 - val_accuracy: 0.0103 - val_loss: 24.6823\n",
      "Epoch 52/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0805 - loss: 3.4515 - val_accuracy: 0.0051 - val_loss: 24.9920\n",
      "Epoch 53/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1000 - loss: 3.4002 - val_accuracy: 0.0103 - val_loss: 25.0714\n",
      "Epoch 54/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0893 - loss: 3.3872 - val_accuracy: 0.0120 - val_loss: 25.5757\n",
      "Epoch 55/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0834 - loss: 3.4354 - val_accuracy: 0.0051 - val_loss: 25.7171\n",
      "Epoch 56/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1062 - loss: 3.3640 - val_accuracy: 0.0000e+00 - val_loss: 25.7053\n",
      "Epoch 57/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1067 - loss: 3.3219 - val_accuracy: 0.0017 - val_loss: 25.7491\n",
      "Epoch 58/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0871 - loss: 3.3241 - val_accuracy: 0.0171 - val_loss: 26.2647\n",
      "Epoch 59/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0943 - loss: 3.3291 - val_accuracy: 0.0051 - val_loss: 25.8171\n",
      "Epoch 60/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0892 - loss: 3.3073 - val_accuracy: 0.0171 - val_loss: 26.5899\n",
      "Epoch 61/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1001 - loss: 3.2712 - val_accuracy: 0.0085 - val_loss: 26.6580\n",
      "Epoch 62/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0928 - loss: 3.3013 - val_accuracy: 0.0085 - val_loss: 26.5574\n",
      "Epoch 63/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1225 - loss: 3.2100 - val_accuracy: 0.0068 - val_loss: 27.2207\n",
      "Epoch 64/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0953 - loss: 3.2583 - val_accuracy: 0.0171 - val_loss: 26.8300\n",
      "Epoch 65/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.0994 - loss: 3.2562 - val_accuracy: 0.0171 - val_loss: 27.0243\n",
      "Epoch 66/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.1033 - loss: 3.2136 - val_accuracy: 0.0085 - val_loss: 27.3655\n",
      "Epoch 67/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0916 - loss: 3.2319 - val_accuracy: 0.0103 - val_loss: 27.5317\n",
      "Epoch 68/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0918 - loss: 3.1850 - val_accuracy: 0.0000e+00 - val_loss: 27.5296\n",
      "Epoch 69/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0926 - loss: 3.2306 - val_accuracy: 0.0205 - val_loss: 28.1308\n",
      "Epoch 70/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1246 - loss: 3.1040 - val_accuracy: 0.0137 - val_loss: 28.0901\n",
      "Epoch 71/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1109 - loss: 3.1645 - val_accuracy: 0.0068 - val_loss: 28.2812\n",
      "Epoch 72/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1129 - loss: 3.1368 - val_accuracy: 0.0137 - val_loss: 28.4366\n",
      "Epoch 73/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1247 - loss: 3.0813 - val_accuracy: 0.0120 - val_loss: 28.9932\n",
      "Epoch 74/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1174 - loss: 3.1148 - val_accuracy: 0.0188 - val_loss: 28.8052\n",
      "Epoch 75/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1058 - loss: 3.1010 - val_accuracy: 0.0154 - val_loss: 28.5954\n",
      "Epoch 76/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1157 - loss: 3.0695 - val_accuracy: 0.0188 - val_loss: 29.0250\n",
      "Epoch 77/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1237 - loss: 3.0676 - val_accuracy: 0.0068 - val_loss: 28.8941\n",
      "Epoch 78/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1257 - loss: 3.0233 - val_accuracy: 0.0222 - val_loss: 29.4094\n",
      "Epoch 79/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1122 - loss: 3.0507 - val_accuracy: 0.0308 - val_loss: 29.2608\n",
      "Epoch 80/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1158 - loss: 2.9780 - val_accuracy: 0.0171 - val_loss: 29.8529\n",
      "Epoch 81/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1282 - loss: 3.0288 - val_accuracy: 0.0256 - val_loss: 30.0815\n",
      "Epoch 82/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1085 - loss: 3.0059 - val_accuracy: 0.0205 - val_loss: 29.9508\n",
      "Epoch 83/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1482 - loss: 2.9454 - val_accuracy: 0.0291 - val_loss: 29.8745\n",
      "Epoch 84/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1425 - loss: 2.9772 - val_accuracy: 0.0256 - val_loss: 29.7696\n",
      "Epoch 85/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1621 - loss: 2.9102 - val_accuracy: 0.0342 - val_loss: 30.7450\n",
      "Epoch 86/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1284 - loss: 2.9544 - val_accuracy: 0.0274 - val_loss: 30.6821\n",
      "Epoch 87/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1305 - loss: 2.8944 - val_accuracy: 0.0154 - val_loss: 30.5774\n",
      "Epoch 88/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1400 - loss: 2.9197 - val_accuracy: 0.0239 - val_loss: 30.9413\n",
      "Epoch 89/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1416 - loss: 2.8915 - val_accuracy: 0.0205 - val_loss: 30.5311\n",
      "Epoch 90/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1356 - loss: 2.9298 - val_accuracy: 0.0222 - val_loss: 30.6950\n",
      "Epoch 91/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1447 - loss: 2.9067 - val_accuracy: 0.0462 - val_loss: 30.8735\n",
      "Epoch 92/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1349 - loss: 2.8626 - val_accuracy: 0.0205 - val_loss: 31.0271\n",
      "Epoch 93/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1386 - loss: 2.8811 - val_accuracy: 0.0308 - val_loss: 31.1559\n",
      "Epoch 94/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1441 - loss: 2.8964 - val_accuracy: 0.0222 - val_loss: 31.3620\n",
      "Epoch 95/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1469 - loss: 2.8863 - val_accuracy: 0.0308 - val_loss: 31.3070\n",
      "Epoch 96/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1535 - loss: 2.8554 - val_accuracy: 0.0222 - val_loss: 31.3789\n",
      "Epoch 97/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1515 - loss: 2.7973 - val_accuracy: 0.0205 - val_loss: 31.2025\n",
      "Epoch 98/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.1520 - loss: 2.8080 - val_accuracy: 0.0325 - val_loss: 31.3486\n",
      "Epoch 99/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1589 - loss: 2.8114 - val_accuracy: 0.0342 - val_loss: 31.7862\n",
      "Epoch 100/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1444 - loss: 2.8381 - val_accuracy: 0.0154 - val_loss: 31.6667\n",
      "Epoch 101/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.1657 - loss: 2.7952 - val_accuracy: 0.0274 - val_loss: 32.1834\n",
      "Epoch 102/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1513 - loss: 2.8101 - val_accuracy: 0.0308 - val_loss: 31.9318\n",
      "Epoch 103/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1559 - loss: 2.7726 - val_accuracy: 0.0564 - val_loss: 32.2488\n",
      "Epoch 104/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1514 - loss: 2.7469 - val_accuracy: 0.0274 - val_loss: 32.0555\n",
      "Epoch 105/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1717 - loss: 2.7323 - val_accuracy: 0.0325 - val_loss: 32.4026\n",
      "Epoch 106/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1659 - loss: 2.7573 - val_accuracy: 0.0239 - val_loss: 32.5991\n",
      "Epoch 107/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1655 - loss: 2.7279 - val_accuracy: 0.0376 - val_loss: 32.6484\n",
      "Epoch 108/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1746 - loss: 2.6869 - val_accuracy: 0.0393 - val_loss: 32.5278\n",
      "Epoch 109/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1687 - loss: 2.6779 - val_accuracy: 0.0444 - val_loss: 32.6333\n",
      "Epoch 110/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1644 - loss: 2.7285 - val_accuracy: 0.0342 - val_loss: 32.5715\n",
      "Epoch 111/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1695 - loss: 2.6906 - val_accuracy: 0.0444 - val_loss: 32.6606\n",
      "Epoch 112/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1663 - loss: 2.7031 - val_accuracy: 0.0188 - val_loss: 32.8460\n",
      "Epoch 113/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1662 - loss: 2.6787 - val_accuracy: 0.0325 - val_loss: 32.7387\n",
      "Epoch 114/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1848 - loss: 2.6584 - val_accuracy: 0.0205 - val_loss: 32.9520\n",
      "Epoch 115/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1787 - loss: 2.6890 - val_accuracy: 0.0359 - val_loss: 33.1503\n",
      "Epoch 116/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1879 - loss: 2.6257 - val_accuracy: 0.0325 - val_loss: 33.1399\n",
      "Epoch 117/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1896 - loss: 2.6216 - val_accuracy: 0.0410 - val_loss: 33.0503\n",
      "Epoch 118/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1793 - loss: 2.6561 - val_accuracy: 0.0325 - val_loss: 33.0710\n",
      "Epoch 119/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1820 - loss: 2.6139 - val_accuracy: 0.0291 - val_loss: 33.1044\n",
      "Epoch 120/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1904 - loss: 2.6607 - val_accuracy: 0.0444 - val_loss: 33.2774\n",
      "Epoch 121/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1877 - loss: 2.6214 - val_accuracy: 0.0615 - val_loss: 33.2999\n",
      "Epoch 122/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2090 - loss: 2.5782 - val_accuracy: 0.0444 - val_loss: 33.4318\n",
      "Epoch 123/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1968 - loss: 2.5996 - val_accuracy: 0.0410 - val_loss: 33.4148\n",
      "Epoch 124/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2083 - loss: 2.6064 - val_accuracy: 0.0479 - val_loss: 33.5500\n",
      "Epoch 125/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2040 - loss: 2.5801 - val_accuracy: 0.0359 - val_loss: 34.0109\n",
      "Epoch 126/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2056 - loss: 2.5353 - val_accuracy: 0.0291 - val_loss: 33.6613\n",
      "Epoch 127/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2051 - loss: 2.5707 - val_accuracy: 0.0393 - val_loss: 33.7620\n",
      "Epoch 128/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1906 - loss: 2.5530 - val_accuracy: 0.0239 - val_loss: 33.8904\n",
      "Epoch 129/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2097 - loss: 2.5132 - val_accuracy: 0.0393 - val_loss: 33.7500\n",
      "Epoch 130/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2178 - loss: 2.5258 - val_accuracy: 0.0376 - val_loss: 34.0251\n",
      "Epoch 131/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2271 - loss: 2.4862 - val_accuracy: 0.0239 - val_loss: 34.4026\n",
      "Epoch 132/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2341 - loss: 2.4937 - val_accuracy: 0.0291 - val_loss: 34.2248\n",
      "Epoch 133/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2296 - loss: 2.4557 - val_accuracy: 0.0513 - val_loss: 34.4001\n",
      "Epoch 134/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2274 - loss: 2.4873 - val_accuracy: 0.0530 - val_loss: 34.3800\n",
      "Epoch 135/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2144 - loss: 2.5186 - val_accuracy: 0.0547 - val_loss: 34.5062\n",
      "Epoch 136/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2458 - loss: 2.4207 - val_accuracy: 0.0410 - val_loss: 34.6471\n",
      "Epoch 137/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2299 - loss: 2.4395 - val_accuracy: 0.0513 - val_loss: 34.5769\n",
      "Epoch 138/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2319 - loss: 2.4444 - val_accuracy: 0.0427 - val_loss: 34.5923\n",
      "Epoch 139/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2427 - loss: 2.4231 - val_accuracy: 0.0479 - val_loss: 34.8194\n",
      "Epoch 140/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2377 - loss: 2.4430 - val_accuracy: 0.0479 - val_loss: 34.8690\n",
      "Epoch 141/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2436 - loss: 2.4114 - val_accuracy: 0.0444 - val_loss: 34.7008\n",
      "Epoch 142/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2282 - loss: 2.4006 - val_accuracy: 0.0393 - val_loss: 34.7939\n",
      "Epoch 143/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2741 - loss: 2.3547 - val_accuracy: 0.0479 - val_loss: 34.9149\n",
      "Epoch 144/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2294 - loss: 2.3896 - val_accuracy: 0.0376 - val_loss: 35.0887\n",
      "Epoch 145/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2377 - loss: 2.3979 - val_accuracy: 0.0427 - val_loss: 35.1625\n",
      "Epoch 146/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2474 - loss: 2.3491 - val_accuracy: 0.0547 - val_loss: 35.1526\n",
      "Epoch 147/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2464 - loss: 2.3749 - val_accuracy: 0.0393 - val_loss: 35.3363\n",
      "Epoch 148/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2621 - loss: 2.3350 - val_accuracy: 0.0598 - val_loss: 35.5347\n",
      "Epoch 149/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2666 - loss: 2.3468 - val_accuracy: 0.0462 - val_loss: 35.0951\n",
      "Epoch 150/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2584 - loss: 2.3536 - val_accuracy: 0.0598 - val_loss: 34.9341\n",
      "Epoch 151/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2606 - loss: 2.3571 - val_accuracy: 0.0650 - val_loss: 35.2501\n",
      "Epoch 152/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2547 - loss: 2.3027 - val_accuracy: 0.0496 - val_loss: 35.4288\n",
      "Epoch 153/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2551 - loss: 2.3124 - val_accuracy: 0.0410 - val_loss: 35.4328\n",
      "Epoch 154/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2728 - loss: 2.3055 - val_accuracy: 0.0462 - val_loss: 35.6815\n",
      "Epoch 155/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2717 - loss: 2.3033 - val_accuracy: 0.0530 - val_loss: 35.6736\n",
      "Epoch 156/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2765 - loss: 2.2859 - val_accuracy: 0.0513 - val_loss: 35.7088\n",
      "Epoch 157/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2727 - loss: 2.2558 - val_accuracy: 0.0598 - val_loss: 35.8089\n",
      "Epoch 158/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.2719 - loss: 2.2829 - val_accuracy: 0.0632 - val_loss: 36.1092\n",
      "Epoch 159/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2795 - loss: 2.2357 - val_accuracy: 0.0650 - val_loss: 36.0604\n",
      "Epoch 160/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2862 - loss: 2.2419 - val_accuracy: 0.0615 - val_loss: 36.1510\n",
      "Epoch 161/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2858 - loss: 2.1931 - val_accuracy: 0.0615 - val_loss: 36.0521\n",
      "Epoch 162/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.2746 - loss: 2.2173 - val_accuracy: 0.0564 - val_loss: 36.0380\n",
      "Epoch 163/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2790 - loss: 2.1760 - val_accuracy: 0.0564 - val_loss: 36.2394\n",
      "Epoch 164/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2869 - loss: 2.2262 - val_accuracy: 0.0598 - val_loss: 36.0206\n",
      "Epoch 165/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3125 - loss: 2.1874 - val_accuracy: 0.0547 - val_loss: 36.4597\n",
      "Epoch 166/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2951 - loss: 2.1954 - val_accuracy: 0.0479 - val_loss: 36.0978\n",
      "Epoch 167/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2979 - loss: 2.1695 - val_accuracy: 0.0496 - val_loss: 36.3031\n",
      "Epoch 168/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3135 - loss: 2.1168 - val_accuracy: 0.0598 - val_loss: 36.5846\n",
      "Epoch 169/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3041 - loss: 2.1301 - val_accuracy: 0.0581 - val_loss: 36.7107\n",
      "Epoch 170/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3207 - loss: 2.1543 - val_accuracy: 0.0393 - val_loss: 36.7826\n",
      "Epoch 171/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3223 - loss: 2.1039 - val_accuracy: 0.0615 - val_loss: 37.0495\n",
      "Epoch 172/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3150 - loss: 2.0928 - val_accuracy: 0.0530 - val_loss: 37.1759\n",
      "Epoch 173/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3089 - loss: 2.1064 - val_accuracy: 0.0667 - val_loss: 36.9725\n",
      "Epoch 174/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3513 - loss: 2.0472 - val_accuracy: 0.0564 - val_loss: 37.2320\n",
      "Epoch 175/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3138 - loss: 2.0907 - val_accuracy: 0.0564 - val_loss: 37.3080\n",
      "Epoch 176/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3144 - loss: 2.1007 - val_accuracy: 0.0547 - val_loss: 37.4005\n",
      "Epoch 177/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3164 - loss: 2.0796 - val_accuracy: 0.0479 - val_loss: 37.7889\n",
      "Epoch 178/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3307 - loss: 2.0943 - val_accuracy: 0.0598 - val_loss: 37.7770\n",
      "Epoch 179/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3501 - loss: 2.0555 - val_accuracy: 0.0462 - val_loss: 37.6852\n",
      "Epoch 180/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3319 - loss: 2.0692 - val_accuracy: 0.0667 - val_loss: 37.9908\n",
      "Epoch 181/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3392 - loss: 2.0746 - val_accuracy: 0.0598 - val_loss: 37.9928\n",
      "Epoch 182/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3349 - loss: 2.0625 - val_accuracy: 0.0667 - val_loss: 37.9333\n",
      "Epoch 183/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3181 - loss: 2.0204 - val_accuracy: 0.0615 - val_loss: 37.7977\n",
      "Epoch 184/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3583 - loss: 2.0000 - val_accuracy: 0.0530 - val_loss: 37.9071\n",
      "Epoch 185/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3751 - loss: 1.9510 - val_accuracy: 0.0667 - val_loss: 38.0055\n",
      "Epoch 186/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3740 - loss: 1.9669 - val_accuracy: 0.0598 - val_loss: 38.0543\n",
      "Epoch 187/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3652 - loss: 1.9936 - val_accuracy: 0.0547 - val_loss: 38.2798\n",
      "Epoch 188/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3456 - loss: 1.9745 - val_accuracy: 0.0598 - val_loss: 38.8298\n",
      "Epoch 189/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3672 - loss: 1.9405 - val_accuracy: 0.0684 - val_loss: 38.7001\n",
      "Epoch 190/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3635 - loss: 1.9974 - val_accuracy: 0.0547 - val_loss: 38.9966\n",
      "Epoch 191/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3480 - loss: 1.9692 - val_accuracy: 0.0581 - val_loss: 38.8311\n",
      "Epoch 192/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3717 - loss: 1.9126 - val_accuracy: 0.0684 - val_loss: 39.3566\n",
      "Epoch 193/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3656 - loss: 1.9331 - val_accuracy: 0.0598 - val_loss: 38.8696\n",
      "Epoch 194/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3882 - loss: 1.9060 - val_accuracy: 0.0650 - val_loss: 39.1827\n",
      "Epoch 195/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3735 - loss: 1.9232 - val_accuracy: 0.0684 - val_loss: 39.0999\n",
      "Epoch 196/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3647 - loss: 1.9157 - val_accuracy: 0.0462 - val_loss: 39.1273\n",
      "Epoch 197/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3575 - loss: 1.9663 - val_accuracy: 0.0444 - val_loss: 39.1693\n",
      "Epoch 198/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3687 - loss: 1.9341 - val_accuracy: 0.0650 - val_loss: 39.2603\n",
      "Epoch 199/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4026 - loss: 1.8730 - val_accuracy: 0.0615 - val_loss: 39.7115\n",
      "Epoch 200/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3584 - loss: 1.9298 - val_accuracy: 0.0650 - val_loss: 39.5724\n",
      "Epoch 201/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3963 - loss: 1.8575 - val_accuracy: 0.0530 - val_loss: 39.5963\n",
      "Epoch 202/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3788 - loss: 1.8947 - val_accuracy: 0.0667 - val_loss: 39.7377\n",
      "Epoch 203/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4048 - loss: 1.8314 - val_accuracy: 0.0615 - val_loss: 39.9682\n",
      "Epoch 204/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3812 - loss: 1.8973 - val_accuracy: 0.0564 - val_loss: 39.8540\n",
      "Epoch 205/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4138 - loss: 1.8369 - val_accuracy: 0.0667 - val_loss: 40.0668\n",
      "Epoch 206/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4125 - loss: 1.7864 - val_accuracy: 0.0632 - val_loss: 40.0059\n",
      "Epoch 207/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3885 - loss: 1.8522 - val_accuracy: 0.0667 - val_loss: 39.8935\n",
      "Epoch 208/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3974 - loss: 1.8197 - val_accuracy: 0.0667 - val_loss: 40.0637\n",
      "Epoch 209/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4029 - loss: 1.8140 - val_accuracy: 0.0632 - val_loss: 40.0144\n",
      "Epoch 210/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3834 - loss: 1.8206 - val_accuracy: 0.0547 - val_loss: 39.8241\n",
      "Epoch 211/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3826 - loss: 1.8622 - val_accuracy: 0.0598 - val_loss: 40.1079\n",
      "Epoch 212/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4186 - loss: 1.7784 - val_accuracy: 0.0650 - val_loss: 40.2883\n",
      "Epoch 213/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4176 - loss: 1.7423 - val_accuracy: 0.0684 - val_loss: 40.6463\n",
      "Epoch 214/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4278 - loss: 1.7180 - val_accuracy: 0.0581 - val_loss: 40.5645\n",
      "Epoch 215/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4198 - loss: 1.7955 - val_accuracy: 0.0684 - val_loss: 40.8252\n",
      "Epoch 216/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4359 - loss: 1.7225 - val_accuracy: 0.0650 - val_loss: 40.8762\n",
      "Epoch 217/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4170 - loss: 1.7654 - val_accuracy: 0.0667 - val_loss: 40.6505\n",
      "Epoch 218/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4303 - loss: 1.7466 - val_accuracy: 0.0632 - val_loss: 40.9853\n",
      "Epoch 219/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4386 - loss: 1.7305 - val_accuracy: 0.0650 - val_loss: 41.0704\n",
      "Epoch 220/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4193 - loss: 1.7758 - val_accuracy: 0.0615 - val_loss: 41.1428\n",
      "Epoch 221/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4295 - loss: 1.7233 - val_accuracy: 0.0615 - val_loss: 41.4776\n",
      "Epoch 222/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4370 - loss: 1.7322 - val_accuracy: 0.0684 - val_loss: 41.0293\n",
      "Epoch 223/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4224 - loss: 1.7405 - val_accuracy: 0.0667 - val_loss: 41.2412\n",
      "Epoch 224/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4591 - loss: 1.6627 - val_accuracy: 0.0667 - val_loss: 41.2297\n",
      "Epoch 225/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4613 - loss: 1.6423 - val_accuracy: 0.0684 - val_loss: 41.0384\n",
      "Epoch 226/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4563 - loss: 1.6536 - val_accuracy: 0.0684 - val_loss: 41.2378\n",
      "Epoch 227/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4720 - loss: 1.6302 - val_accuracy: 0.0667 - val_loss: 41.3119\n",
      "Epoch 228/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4543 - loss: 1.6172 - val_accuracy: 0.0632 - val_loss: 41.3857\n",
      "Epoch 229/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4706 - loss: 1.6267 - val_accuracy: 0.0650 - val_loss: 41.2636\n",
      "Epoch 230/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4502 - loss: 1.6711 - val_accuracy: 0.0684 - val_loss: 41.4118\n",
      "Epoch 231/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4598 - loss: 1.6460 - val_accuracy: 0.0650 - val_loss: 41.4494\n",
      "Epoch 232/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4639 - loss: 1.6529 - val_accuracy: 0.0667 - val_loss: 41.3198\n",
      "Epoch 233/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4714 - loss: 1.6503 - val_accuracy: 0.0667 - val_loss: 41.5016\n",
      "Epoch 234/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4765 - loss: 1.6338 - val_accuracy: 0.0667 - val_loss: 41.9632\n",
      "Epoch 235/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4701 - loss: 1.6046 - val_accuracy: 0.0667 - val_loss: 41.7050\n",
      "Epoch 236/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4817 - loss: 1.5877 - val_accuracy: 0.0667 - val_loss: 41.6392\n",
      "Epoch 237/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4733 - loss: 1.6281 - val_accuracy: 0.0701 - val_loss: 41.8084\n",
      "Epoch 238/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4837 - loss: 1.5752 - val_accuracy: 0.0650 - val_loss: 41.6675\n",
      "Epoch 239/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4811 - loss: 1.5862 - val_accuracy: 0.0667 - val_loss: 41.6010\n",
      "Epoch 240/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4780 - loss: 1.6012 - val_accuracy: 0.0684 - val_loss: 41.7464\n",
      "Epoch 241/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4780 - loss: 1.6181 - val_accuracy: 0.0684 - val_loss: 41.7567\n",
      "Epoch 242/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4953 - loss: 1.6229 - val_accuracy: 0.0684 - val_loss: 41.7825\n",
      "Epoch 243/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4837 - loss: 1.5394 - val_accuracy: 0.0684 - val_loss: 41.9303\n",
      "Epoch 244/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4722 - loss: 1.5533 - val_accuracy: 0.0684 - val_loss: 41.9990\n",
      "Epoch 245/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4816 - loss: 1.5623 - val_accuracy: 0.0684 - val_loss: 41.7094\n",
      "Epoch 246/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5097 - loss: 1.4799 - val_accuracy: 0.0650 - val_loss: 42.3225\n",
      "Epoch 247/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5068 - loss: 1.5008 - val_accuracy: 0.0684 - val_loss: 42.2787\n",
      "Epoch 248/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4999 - loss: 1.5183 - val_accuracy: 0.0615 - val_loss: 42.2378\n",
      "Epoch 249/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5102 - loss: 1.4752 - val_accuracy: 0.0598 - val_loss: 42.2941\n",
      "Epoch 250/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5002 - loss: 1.4641 - val_accuracy: 0.0632 - val_loss: 42.9817\n",
      "Epoch 251/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5103 - loss: 1.4827 - val_accuracy: 0.0615 - val_loss: 42.3995\n",
      "Epoch 252/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5153 - loss: 1.4604 - val_accuracy: 0.0701 - val_loss: 42.7180\n",
      "Epoch 253/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5476 - loss: 1.4711 - val_accuracy: 0.0684 - val_loss: 42.8155\n",
      "Epoch 254/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5115 - loss: 1.4867 - val_accuracy: 0.0684 - val_loss: 43.1967\n",
      "Epoch 255/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5114 - loss: 1.4764 - val_accuracy: 0.0701 - val_loss: 43.7185\n",
      "Epoch 256/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4906 - loss: 1.4900 - val_accuracy: 0.0684 - val_loss: 43.6407\n",
      "Epoch 257/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5192 - loss: 1.4430 - val_accuracy: 0.0684 - val_loss: 43.5308\n",
      "Epoch 258/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5551 - loss: 1.3839 - val_accuracy: 0.0667 - val_loss: 43.7429\n",
      "Epoch 259/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5197 - loss: 1.4619 - val_accuracy: 0.0667 - val_loss: 43.4960\n",
      "Epoch 260/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5338 - loss: 1.4495 - val_accuracy: 0.0684 - val_loss: 43.7800\n",
      "Epoch 261/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5263 - loss: 1.4371 - val_accuracy: 0.0701 - val_loss: 44.1027\n",
      "Epoch 262/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5567 - loss: 1.3991 - val_accuracy: 0.0684 - val_loss: 43.7760\n",
      "Epoch 263/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5398 - loss: 1.3942 - val_accuracy: 0.0684 - val_loss: 44.6494\n",
      "Epoch 264/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5197 - loss: 1.4642 - val_accuracy: 0.0632 - val_loss: 44.2977\n",
      "Epoch 265/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5111 - loss: 1.4417 - val_accuracy: 0.0684 - val_loss: 44.4190\n",
      "Epoch 266/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5485 - loss: 1.3849 - val_accuracy: 0.0684 - val_loss: 44.3248\n",
      "Epoch 267/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5366 - loss: 1.4105 - val_accuracy: 0.0684 - val_loss: 44.5787\n",
      "Epoch 268/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5411 - loss: 1.3952 - val_accuracy: 0.0701 - val_loss: 44.7023\n",
      "Epoch 269/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5572 - loss: 1.3460 - val_accuracy: 0.0598 - val_loss: 44.4556\n",
      "Epoch 270/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5501 - loss: 1.3753 - val_accuracy: 0.0701 - val_loss: 44.6728\n",
      "Epoch 271/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5547 - loss: 1.3309 - val_accuracy: 0.0684 - val_loss: 44.8857\n",
      "Epoch 272/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5629 - loss: 1.3156 - val_accuracy: 0.0684 - val_loss: 44.6947\n",
      "Epoch 273/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5689 - loss: 1.3173 - val_accuracy: 0.0684 - val_loss: 44.5928\n",
      "Epoch 274/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5670 - loss: 1.3355 - val_accuracy: 0.0701 - val_loss: 44.4464\n",
      "Epoch 275/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5704 - loss: 1.3049 - val_accuracy: 0.0701 - val_loss: 44.9451\n",
      "Epoch 276/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5564 - loss: 1.3560 - val_accuracy: 0.0684 - val_loss: 44.9759\n",
      "Epoch 277/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5671 - loss: 1.3321 - val_accuracy: 0.0684 - val_loss: 44.8967\n",
      "Epoch 278/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5809 - loss: 1.3479 - val_accuracy: 0.0684 - val_loss: 44.5851\n",
      "Epoch 279/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5614 - loss: 1.3045 - val_accuracy: 0.0684 - val_loss: 44.9118\n",
      "Epoch 280/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5805 - loss: 1.2873 - val_accuracy: 0.0684 - val_loss: 44.6522\n",
      "Epoch 281/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5898 - loss: 1.2706 - val_accuracy: 0.0701 - val_loss: 45.0641\n",
      "Epoch 282/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5848 - loss: 1.2841 - val_accuracy: 0.0684 - val_loss: 44.7167\n",
      "Epoch 283/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5828 - loss: 1.2549 - val_accuracy: 0.0701 - val_loss: 45.1698\n",
      "Epoch 284/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5930 - loss: 1.2727 - val_accuracy: 0.0701 - val_loss: 44.9230\n",
      "Epoch 285/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5750 - loss: 1.2785 - val_accuracy: 0.0684 - val_loss: 45.0636\n",
      "Epoch 286/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5805 - loss: 1.3098 - val_accuracy: 0.0701 - val_loss: 45.2041\n",
      "Epoch 287/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5773 - loss: 1.2957 - val_accuracy: 0.0701 - val_loss: 45.1997\n",
      "Epoch 288/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5738 - loss: 1.2996 - val_accuracy: 0.0701 - val_loss: 45.1855\n",
      "Epoch 289/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5893 - loss: 1.2980 - val_accuracy: 0.0667 - val_loss: 45.1302\n",
      "Epoch 290/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6137 - loss: 1.2367 - val_accuracy: 0.0701 - val_loss: 44.9760\n",
      "Epoch 291/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6034 - loss: 1.2190 - val_accuracy: 0.0701 - val_loss: 45.2498\n",
      "Epoch 292/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5750 - loss: 1.2862 - val_accuracy: 0.0701 - val_loss: 45.3101\n",
      "Epoch 293/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5894 - loss: 1.2709 - val_accuracy: 0.0701 - val_loss: 45.1303\n",
      "Epoch 294/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6270 - loss: 1.1545 - val_accuracy: 0.0701 - val_loss: 45.0880\n",
      "Epoch 295/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5975 - loss: 1.2638 - val_accuracy: 0.0701 - val_loss: 45.3472\n",
      "Epoch 296/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5998 - loss: 1.2425 - val_accuracy: 0.0684 - val_loss: 45.4304\n",
      "Epoch 297/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6031 - loss: 1.2035 - val_accuracy: 0.0684 - val_loss: 45.4050\n",
      "Epoch 298/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6258 - loss: 1.1405 - val_accuracy: 0.0684 - val_loss: 45.4701\n",
      "Epoch 299/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6079 - loss: 1.2259 - val_accuracy: 0.0701 - val_loss: 45.7003\n",
      "Epoch 300/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6064 - loss: 1.1752 - val_accuracy: 0.0701 - val_loss: 45.6248\n",
      "Epoch 301/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5910 - loss: 1.2250 - val_accuracy: 0.0701 - val_loss: 45.6385\n",
      "Epoch 302/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6229 - loss: 1.1451 - val_accuracy: 0.0701 - val_loss: 45.1390\n",
      "Epoch 303/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6160 - loss: 1.2278 - val_accuracy: 0.0701 - val_loss: 45.4529\n",
      "Epoch 304/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6129 - loss: 1.1745 - val_accuracy: 0.0701 - val_loss: 45.1691\n",
      "Epoch 305/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6380 - loss: 1.1203 - val_accuracy: 0.0701 - val_loss: 45.6083\n",
      "Epoch 306/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6316 - loss: 1.1423 - val_accuracy: 0.0701 - val_loss: 45.6957\n",
      "Epoch 307/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6101 - loss: 1.1711 - val_accuracy: 0.0684 - val_loss: 45.3323\n",
      "Epoch 308/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6085 - loss: 1.1847 - val_accuracy: 0.0701 - val_loss: 45.3185\n",
      "Epoch 309/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6143 - loss: 1.1583 - val_accuracy: 0.0701 - val_loss: 45.5672\n",
      "Epoch 310/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6311 - loss: 1.1461 - val_accuracy: 0.0667 - val_loss: 45.8194\n",
      "Epoch 311/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6350 - loss: 1.1259 - val_accuracy: 0.0701 - val_loss: 45.8662\n",
      "Epoch 312/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6365 - loss: 1.1082 - val_accuracy: 0.0701 - val_loss: 45.7347\n",
      "Epoch 313/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6581 - loss: 1.1203 - val_accuracy: 0.0701 - val_loss: 46.1516\n",
      "Epoch 314/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6274 - loss: 1.1059 - val_accuracy: 0.0701 - val_loss: 46.2580\n",
      "Epoch 315/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6417 - loss: 1.0947 - val_accuracy: 0.0701 - val_loss: 46.3876\n",
      "Epoch 316/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6452 - loss: 1.0792 - val_accuracy: 0.0701 - val_loss: 46.4790\n",
      "Epoch 317/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6371 - loss: 1.0673 - val_accuracy: 0.0701 - val_loss: 46.4431\n",
      "Epoch 318/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6500 - loss: 1.1048 - val_accuracy: 0.0684 - val_loss: 46.3508\n",
      "Epoch 319/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6454 - loss: 1.0561 - val_accuracy: 0.0684 - val_loss: 46.0845\n",
      "Epoch 320/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6733 - loss: 1.0182 - val_accuracy: 0.0701 - val_loss: 46.4029\n",
      "Epoch 321/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6739 - loss: 1.0514 - val_accuracy: 0.0701 - val_loss: 46.7113\n",
      "Epoch 322/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6344 - loss: 1.0768 - val_accuracy: 0.0701 - val_loss: 46.5818\n",
      "Epoch 323/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6347 - loss: 1.0654 - val_accuracy: 0.0701 - val_loss: 46.5106\n",
      "Epoch 324/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6426 - loss: 1.0875 - val_accuracy: 0.0701 - val_loss: 46.5843\n",
      "Epoch 325/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6689 - loss: 1.0222 - val_accuracy: 0.0701 - val_loss: 46.7717\n",
      "Epoch 326/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6542 - loss: 1.0654 - val_accuracy: 0.0701 - val_loss: 46.6215\n",
      "Epoch 327/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6604 - loss: 1.0233 - val_accuracy: 0.0684 - val_loss: 46.7769\n",
      "Epoch 328/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6387 - loss: 1.0513 - val_accuracy: 0.0684 - val_loss: 46.9010\n",
      "Epoch 329/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6340 - loss: 1.0537 - val_accuracy: 0.0701 - val_loss: 47.4546\n",
      "Epoch 330/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6474 - loss: 1.0678 - val_accuracy: 0.0701 - val_loss: 47.3580\n",
      "Epoch 331/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6646 - loss: 1.0304 - val_accuracy: 0.0701 - val_loss: 47.1490\n",
      "Epoch 332/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6450 - loss: 1.0308 - val_accuracy: 0.0701 - val_loss: 47.3406\n",
      "Epoch 333/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6525 - loss: 1.0657 - val_accuracy: 0.0701 - val_loss: 47.7318\n",
      "Epoch 334/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6665 - loss: 1.0080 - val_accuracy: 0.0701 - val_loss: 47.3597\n",
      "Epoch 335/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6817 - loss: 1.0104 - val_accuracy: 0.0701 - val_loss: 47.4346\n",
      "Epoch 336/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6554 - loss: 1.0361 - val_accuracy: 0.0701 - val_loss: 47.4042\n",
      "Epoch 337/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7037 - loss: 0.9569 - val_accuracy: 0.0701 - val_loss: 47.7261\n",
      "Epoch 338/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6790 - loss: 1.0102 - val_accuracy: 0.0701 - val_loss: 47.7691\n",
      "Epoch 339/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6747 - loss: 0.9876 - val_accuracy: 0.0701 - val_loss: 47.5508\n",
      "Epoch 340/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6647 - loss: 0.9942 - val_accuracy: 0.0701 - val_loss: 47.5638\n",
      "Epoch 341/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6828 - loss: 0.9748 - val_accuracy: 0.0701 - val_loss: 47.5102\n",
      "Epoch 342/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6693 - loss: 0.9768 - val_accuracy: 0.0701 - val_loss: 47.5635\n",
      "Epoch 343/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6751 - loss: 1.0086 - val_accuracy: 0.0701 - val_loss: 47.6877\n",
      "Epoch 344/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6739 - loss: 0.9812 - val_accuracy: 0.0701 - val_loss: 47.0835\n",
      "Epoch 345/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6621 - loss: 0.9874 - val_accuracy: 0.0701 - val_loss: 47.3130\n",
      "Epoch 346/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6856 - loss: 0.9668 - val_accuracy: 0.0701 - val_loss: 47.6388\n",
      "Epoch 347/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6864 - loss: 0.9340 - val_accuracy: 0.0701 - val_loss: 47.8789\n",
      "Epoch 348/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6811 - loss: 0.9369 - val_accuracy: 0.0701 - val_loss: 48.0671\n",
      "Epoch 349/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6636 - loss: 1.0314 - val_accuracy: 0.0701 - val_loss: 48.0169\n",
      "Epoch 350/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7009 - loss: 0.9537 - val_accuracy: 0.0701 - val_loss: 48.6012\n",
      "Epoch 351/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6965 - loss: 0.9732 - val_accuracy: 0.0701 - val_loss: 47.6608\n",
      "Epoch 352/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7045 - loss: 0.9143 - val_accuracy: 0.0701 - val_loss: 47.3297\n",
      "Epoch 353/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6747 - loss: 0.9713 - val_accuracy: 0.0701 - val_loss: 47.5872\n",
      "Epoch 354/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6909 - loss: 0.9692 - val_accuracy: 0.0701 - val_loss: 47.5529\n",
      "Epoch 355/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7023 - loss: 0.9282 - val_accuracy: 0.0701 - val_loss: 47.9139\n",
      "Epoch 356/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6707 - loss: 0.9729 - val_accuracy: 0.0701 - val_loss: 48.3602\n",
      "Epoch 357/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6702 - loss: 0.9643 - val_accuracy: 0.0735 - val_loss: 47.5742\n",
      "Epoch 358/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6811 - loss: 0.9709 - val_accuracy: 0.0701 - val_loss: 47.9303\n",
      "Epoch 359/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6867 - loss: 0.9526 - val_accuracy: 0.0701 - val_loss: 48.0279\n",
      "Epoch 360/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7185 - loss: 0.8677 - val_accuracy: 0.0701 - val_loss: 48.0361\n",
      "Epoch 361/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6980 - loss: 0.8992 - val_accuracy: 0.0701 - val_loss: 47.9759\n",
      "Epoch 362/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6943 - loss: 0.9457 - val_accuracy: 0.0701 - val_loss: 47.9899\n",
      "Epoch 363/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7033 - loss: 0.8875 - val_accuracy: 0.0701 - val_loss: 48.1486\n",
      "Epoch 364/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6777 - loss: 0.9651 - val_accuracy: 0.0701 - val_loss: 47.8907\n",
      "Epoch 365/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7206 - loss: 0.8860 - val_accuracy: 0.0701 - val_loss: 47.7894\n",
      "Epoch 366/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7179 - loss: 0.8678 - val_accuracy: 0.0701 - val_loss: 48.3752\n",
      "Epoch 367/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7104 - loss: 0.9361 - val_accuracy: 0.0701 - val_loss: 48.3319\n",
      "Epoch 368/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7108 - loss: 0.8850 - val_accuracy: 0.0701 - val_loss: 48.3623\n",
      "Epoch 369/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7092 - loss: 0.8709 - val_accuracy: 0.0701 - val_loss: 48.7541\n",
      "Epoch 370/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6994 - loss: 0.8893 - val_accuracy: 0.0701 - val_loss: 48.6534\n",
      "Epoch 371/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7066 - loss: 0.8858 - val_accuracy: 0.0701 - val_loss: 48.3366\n",
      "Epoch 372/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7316 - loss: 0.8318 - val_accuracy: 0.0701 - val_loss: 48.7692\n",
      "Epoch 373/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7114 - loss: 0.8881 - val_accuracy: 0.0701 - val_loss: 49.0634\n",
      "Epoch 374/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7201 - loss: 0.8423 - val_accuracy: 0.0701 - val_loss: 49.0406\n",
      "Epoch 375/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6987 - loss: 0.8861 - val_accuracy: 0.0701 - val_loss: 48.8707\n",
      "Epoch 376/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6990 - loss: 0.9063 - val_accuracy: 0.0701 - val_loss: 49.1577\n",
      "Epoch 377/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7229 - loss: 0.8184 - val_accuracy: 0.0701 - val_loss: 49.2325\n",
      "Epoch 378/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7223 - loss: 0.8607 - val_accuracy: 0.0701 - val_loss: 49.6619\n",
      "Epoch 379/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7130 - loss: 0.8440 - val_accuracy: 0.0718 - val_loss: 48.7296\n",
      "Epoch 380/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7191 - loss: 0.8496 - val_accuracy: 0.0701 - val_loss: 49.2950\n",
      "Epoch 381/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7210 - loss: 0.8523 - val_accuracy: 0.0701 - val_loss: 49.5161\n",
      "Epoch 382/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7019 - loss: 0.8713 - val_accuracy: 0.0701 - val_loss: 48.9770\n",
      "Epoch 383/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7040 - loss: 0.8892 - val_accuracy: 0.0701 - val_loss: 49.0284\n",
      "Epoch 384/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7289 - loss: 0.8341 - val_accuracy: 0.0718 - val_loss: 49.4071\n",
      "Epoch 385/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7201 - loss: 0.8757 - val_accuracy: 0.0718 - val_loss: 49.1509\n",
      "Epoch 386/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7368 - loss: 0.7992 - val_accuracy: 0.0718 - val_loss: 49.3594\n",
      "Epoch 387/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7242 - loss: 0.8014 - val_accuracy: 0.0735 - val_loss: 49.3387\n",
      "Epoch 388/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7218 - loss: 0.8559 - val_accuracy: 0.0701 - val_loss: 49.1168\n",
      "Epoch 389/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7236 - loss: 0.8461 - val_accuracy: 0.0701 - val_loss: 49.6193\n",
      "Epoch 390/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7059 - loss: 0.8531 - val_accuracy: 0.0735 - val_loss: 49.0761\n",
      "Epoch 391/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7455 - loss: 0.8040 - val_accuracy: 0.0735 - val_loss: 49.5271\n",
      "Epoch 392/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7255 - loss: 0.8424 - val_accuracy: 0.0735 - val_loss: 49.8881\n",
      "Epoch 393/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7217 - loss: 0.8620 - val_accuracy: 0.0718 - val_loss: 50.2422\n",
      "Epoch 394/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6988 - loss: 0.8756 - val_accuracy: 0.0735 - val_loss: 50.2065\n",
      "Epoch 395/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7422 - loss: 0.7901 - val_accuracy: 0.0735 - val_loss: 50.2822\n",
      "Epoch 396/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7366 - loss: 0.8104 - val_accuracy: 0.0684 - val_loss: 50.7749\n",
      "Epoch 397/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7342 - loss: 0.8096 - val_accuracy: 0.0684 - val_loss: 51.0045\n",
      "Epoch 398/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7525 - loss: 0.8033 - val_accuracy: 0.0701 - val_loss: 51.0960\n",
      "Epoch 399/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7432 - loss: 0.7744 - val_accuracy: 0.0735 - val_loss: 50.7174\n",
      "Epoch 400/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7288 - loss: 0.8247 - val_accuracy: 0.0718 - val_loss: 50.7666\n",
      "Epoch 401/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7450 - loss: 0.8090 - val_accuracy: 0.0735 - val_loss: 50.7952\n",
      "Epoch 402/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7428 - loss: 0.7771 - val_accuracy: 0.0735 - val_loss: 50.7751\n",
      "Epoch 403/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7430 - loss: 0.8224 - val_accuracy: 0.0735 - val_loss: 50.5438\n",
      "Epoch 404/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7541 - loss: 0.7726 - val_accuracy: 0.0718 - val_loss: 50.7352\n",
      "Epoch 405/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7304 - loss: 0.8171 - val_accuracy: 0.0701 - val_loss: 50.8208\n",
      "Epoch 406/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7410 - loss: 0.7814 - val_accuracy: 0.0701 - val_loss: 50.7328\n",
      "Epoch 407/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7326 - loss: 0.7575 - val_accuracy: 0.0701 - val_loss: 50.8006\n",
      "Epoch 408/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7422 - loss: 0.8120 - val_accuracy: 0.0701 - val_loss: 50.7463\n",
      "Epoch 409/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7268 - loss: 0.8236 - val_accuracy: 0.0718 - val_loss: 50.5074\n",
      "Epoch 410/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7513 - loss: 0.7750 - val_accuracy: 0.0735 - val_loss: 50.4326\n",
      "Epoch 411/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7291 - loss: 0.7864 - val_accuracy: 0.0735 - val_loss: 50.5278\n",
      "Epoch 412/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7448 - loss: 0.7712 - val_accuracy: 0.0735 - val_loss: 50.7160\n",
      "Epoch 413/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7479 - loss: 0.7619 - val_accuracy: 0.0718 - val_loss: 50.4932\n",
      "Epoch 414/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7446 - loss: 0.7625 - val_accuracy: 0.0735 - val_loss: 50.8743\n",
      "Epoch 415/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7354 - loss: 0.7842 - val_accuracy: 0.0735 - val_loss: 50.9360\n",
      "Epoch 416/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7488 - loss: 0.7676 - val_accuracy: 0.0735 - val_loss: 50.4838\n",
      "Epoch 417/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7482 - loss: 0.7638 - val_accuracy: 0.0701 - val_loss: 51.3915\n",
      "Epoch 418/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7672 - loss: 0.7208 - val_accuracy: 0.0718 - val_loss: 51.1820\n",
      "Epoch 419/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.7272 - val_accuracy: 0.0735 - val_loss: 51.0790\n",
      "Epoch 420/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7513 - loss: 0.7751 - val_accuracy: 0.0718 - val_loss: 51.2309\n",
      "Epoch 421/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7489 - loss: 0.7513 - val_accuracy: 0.0718 - val_loss: 51.2241\n",
      "Epoch 422/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7481 - loss: 0.7698 - val_accuracy: 0.0718 - val_loss: 51.1361\n",
      "Epoch 423/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7734 - loss: 0.7183 - val_accuracy: 0.0718 - val_loss: 51.3065\n",
      "Epoch 424/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7541 - loss: 0.7673 - val_accuracy: 0.0735 - val_loss: 51.1138\n",
      "Epoch 425/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7603 - loss: 0.7565 - val_accuracy: 0.0735 - val_loss: 51.2229\n",
      "Epoch 426/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7831 - loss: 0.6635 - val_accuracy: 0.0735 - val_loss: 50.8845\n",
      "Epoch 427/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7610 - loss: 0.7564 - val_accuracy: 0.0735 - val_loss: 51.2047\n",
      "Epoch 428/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7859 - loss: 0.6974 - val_accuracy: 0.0735 - val_loss: 51.3102\n",
      "Epoch 429/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7580 - loss: 0.6923 - val_accuracy: 0.0735 - val_loss: 51.5676\n",
      "Epoch 430/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7381 - loss: 0.7839 - val_accuracy: 0.0735 - val_loss: 51.6215\n",
      "Epoch 431/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7631 - loss: 0.7476 - val_accuracy: 0.0735 - val_loss: 51.4764\n",
      "Epoch 432/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7725 - loss: 0.7167 - val_accuracy: 0.0701 - val_loss: 51.7342\n",
      "Epoch 433/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7615 - loss: 0.7107 - val_accuracy: 0.0735 - val_loss: 52.0183\n",
      "Epoch 434/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7579 - loss: 0.7344 - val_accuracy: 0.0701 - val_loss: 51.7566\n",
      "Epoch 435/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7900 - loss: 0.6756 - val_accuracy: 0.0701 - val_loss: 51.9349\n",
      "Epoch 436/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7794 - loss: 0.6770 - val_accuracy: 0.0701 - val_loss: 52.1801\n",
      "Epoch 437/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7688 - loss: 0.7463 - val_accuracy: 0.0718 - val_loss: 52.0278\n",
      "Epoch 438/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7780 - loss: 0.7282 - val_accuracy: 0.0701 - val_loss: 51.5032\n",
      "Epoch 439/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7661 - loss: 0.7203 - val_accuracy: 0.0701 - val_loss: 51.6995\n",
      "Epoch 440/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7785 - loss: 0.7014 - val_accuracy: 0.0701 - val_loss: 52.2297\n",
      "Epoch 441/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7690 - loss: 0.7083 - val_accuracy: 0.0701 - val_loss: 52.5270\n",
      "Epoch 442/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7964 - loss: 0.6526 - val_accuracy: 0.0718 - val_loss: 51.9292\n",
      "Epoch 443/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7618 - loss: 0.7297 - val_accuracy: 0.0735 - val_loss: 52.0305\n",
      "Epoch 444/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7716 - loss: 0.7219 - val_accuracy: 0.0701 - val_loss: 52.0179\n",
      "Epoch 445/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7783 - loss: 0.6855 - val_accuracy: 0.0735 - val_loss: 52.0664\n",
      "Epoch 446/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7830 - loss: 0.6539 - val_accuracy: 0.0735 - val_loss: 51.7101\n",
      "Epoch 447/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7784 - loss: 0.6672 - val_accuracy: 0.0735 - val_loss: 51.7526\n",
      "Epoch 448/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7870 - loss: 0.6587 - val_accuracy: 0.0718 - val_loss: 51.9950\n",
      "Epoch 449/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7875 - loss: 0.6585 - val_accuracy: 0.0718 - val_loss: 51.6087\n",
      "Epoch 450/450\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7857 - loss: 0.6627 - val_accuracy: 0.0735 - val_loss: 51.9690\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "history = model.fit(\n",
    "    X_pad, y,\n",
    "    epochs=450,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,750</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m40,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m)            │        \u001b[38;5;34m24,750\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">385,004</span> (1.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m385,004\u001b[0m (1.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,334</span> (501.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,334\u001b[0m (501.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256,670</span> (1002.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m256,670\u001b[0m (1002.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk generate response\n",
    "def generate_response(user_input):\n",
    "    # Preprocess input\n",
    "    user_input = user_input.lower()\n",
    "    input_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "    input_padded = pad_sequences(input_sequence, maxlen=max_seq_len, padding='post')\n",
    "\n",
    "    # Predict tag\n",
    "    prediction = model.predict(input_padded, verbose=0)\n",
    "    predicted_tag_index = np.argmax(prediction, axis=-1)[0]\n",
    "    predicted_tag = label_encoder.inverse_transform([predicted_tag_index])[0]\n",
    "\n",
    "    # Get confidence score\n",
    "    confidence = np.max(prediction)\n",
    "\n",
    "    # Get response if confidence is above threshold\n",
    "    if confidence > 0.9:  # You can adjust this threshold\n",
    "        matching_responses = df[df['tag'] == predicted_tag]['responses'].values\n",
    "        if len(matching_responses) > 0:\n",
    "            responses = matching_responses[0]\n",
    "            return np.random.choice(responses), confidence\n",
    "\n",
    "    return \"Maaf, saya tidak yakin dengan jawaban untuk pertanyaan ini.\", confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "\n",
      "Input: hi\n",
      "Response: Hai! Selamat datang di layanan Unibot. Ada info kampus yang ingin kamu cari?\n",
      "Confidence: 100.00%\n",
      "\n",
      "Input: Kampus yang berada di Jakarta Barat?\n",
      "Response: Berikut adalah daftar universitas di Jakarta Barat:\n",
      "1. Universitas Kristen Krida Wacana\n",
      "2. Universitas Satyagama\n",
      "3. Universitas Bina Nusantara\n",
      "4. Universitas Dian Nusantara\n",
      "5. Universitas Media Nusantara Citra\n",
      "6. Universitas Esa Unggul\n",
      "7. Universitas Agung Podomoro\n",
      "8. Universitas Trisakti\n",
      "9. Universitas Tarumanagara\n",
      "10. Universitas Mercu Buana\n",
      "11. Universitas Timbul Nusantara\n",
      "Confidence: 100.00%\n",
      "\n",
      "Input: Unibot, yang buat kamu siapa sih?\n",
      "Response: Penciptaku adalah mahasiswa dari Universitas Tarumanagara. Berkat ide-ide nya, saya bisa hadir dan membantu kamu saat ini!\n",
      "Confidence: 100.00%\n",
      "\n",
      "Input: Berapa biaya kuliah di Universitas Muhammadiyah Jakarta?\n",
      "Response: Biaya per semester di Universitas Muhammadiyah Jakarta (UMJ) berkisar antara Rp275.000 hingga Rp21.600.000, tergantung program studi yang dipilih.\n",
      "Confidence: 100.00%\n",
      "\n",
      "Input: bye\n",
      "Response: Bye!\n",
      "Confidence: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_inputs = [\n",
    "    \"hi\",\n",
    "    \"Kampus yang berada di Jakarta Barat?\",\n",
    "    \"Unibot, yang buat kamu siapa sih?\",\n",
    "    \"Berapa biaya kuliah di Universitas Muhammadiyah Jakarta?\",\n",
    "    \"bye\"\n",
    "]\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for input_text in test_inputs:\n",
    "    response, confidence = generate_response(input_text)\n",
    "    print(f\"\\nInput: {input_text}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan komponen pendukung telah disimpan!\n"
     ]
    }
   ],
   "source": [
    "# simpan model dan komponen yang diperlukan\n",
    "import pickle\n",
    "import json\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Simpan model\n",
    "model.save('chatbot_model.h5')\n",
    "\n",
    "# Simpan tokenizer dan label encoder\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Simpan max_seq_len dan responses\n",
    "model_config = {\n",
    "    'max_seq_len': max_seq_len,\n",
    "}\n",
    "with open('model_config.json', 'w') as f:\n",
    "    json.dump(model_config, f)\n",
    "\n",
    "# Simpan responses dictionary\n",
    "responses_dict = {}\n",
    "for _, row in df.iterrows():\n",
    "    tag = row['tag']\n",
    "    if tag not in responses_dict:\n",
    "        responses_dict[tag] = row['responses']\n",
    "\n",
    "with open('responses.json', 'w') as f:\n",
    "    json.dump(responses_dict, f)\n",
    "\n",
    "print(\"Model dan komponen pendukung telah disimpan!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
